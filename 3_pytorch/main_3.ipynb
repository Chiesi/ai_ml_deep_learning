{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "root_dir = './'\n",
    "# Define the tensor transformation and load training and validation data\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,),)\n",
    "    ]\n",
    ")\n",
    "trainset = datasets.MNIST(\n",
    "    root=root_dir,\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform\n",
    ")\n",
    "valset = datasets.MNIST(\n",
    "    root=root_dir,\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll build another multy-layer perceptron, with 784 input units (images are 28x28)\n",
    "# Can you guess the rest of the architecture?\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZPElEQVR4nO3dfWxV9f0H8G9RqKi0WBDaCiiID5sKm06RKYiTgLipoFlk8w80TgYDIzIf0gXFp6TTJZtxYWo2JzNTfEjEpy1NEAXmBI0wRsw2QgkTCA9OEgpUqAbOL+fwo6MKuFvbfm/vfb2Sby73nvPpOT2cnvf9nvO955YkSZIEAOhgXTp6gQCQEkAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEcHfLMvn37wqZNm0KPHj1CSUlJ7NUBIEfp/Q127twZqqurQ5cuXTpPAKXh079//9irAcBXtGHDhtCvX7/Ocwou7fkA0Pl92fG83QJozpw54ZRTTgnHHHNMGDZsWHjvvff+pzqn3QAKw5cdz9slgJ5//vkwc+bMMHv27LBixYowdOjQMHbs2PDRRx+1x+IA6IySdnDBBRck06ZNa36+d+/epLq6Oqmtrf3S2oaGhvTu3JqmaVro3C09nh9Jm/eAPv3007B8+fIwevTo5tfSURDp86VLl35h/qamprBjx44WDYDC1+YB9PHHH4e9e/eGvn37tng9fb5ly5YvzF9bWxvKy8ubmxFwAMUh+ii4mpqa0NDQ0NzSYXsAFL42/xxQ7969w1FHHRW2bt3a4vX0eWVl5RfmLy0tzRoAxaXNe0DdunUL5513Xli4cGGLuxukz4cPH97WiwOgk2qXOyGkQ7AnTZoUvvWtb4ULLrggPPLII6GxsTHceOON7bE4ADqhdgmg6667LvznP/8J99xzTzbw4Bvf+Eaoq6v7wsAEAIpXSToWO+SRdBh2OhoOgM4tHVhWVlaWv6PgAChOAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQxdFxFks+ufXWW1tVd//99+dcU1ZWlnPNvn37Qj77y1/+knPNrFmzcq55++23c66BfKYHBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACicDNSwte//vVW1XXt2jXnmnfeeSfnmtNOOy3nmoqKitBRRowYkXPNSy+9lHPNE088kXPNgw8+GFqjqampVXWQCz0gAKIQQAAURgDde++9oaSkpEU788wz23oxAHRy7XIN6KyzzgpvvPHGfxdytEtNALTULsmQBk5lZWV7/GgACkS7XANas2ZNqK6uDoMGDQrXX399WL9+/RFH2+zYsaNFA6DwtXkADRs2LMydOzfU1dWFxx57LKxbty4bprpz585Dzl9bWxvKy8ubW//+/dt6lQAohgAaN25c+P73vx+GDBkSxo4dG/785z+H7du3hxdeeOGQ89fU1ISGhobmtmHDhrZeJQDyULuPDujZs2c4/fTTQ319/SGnl5aWZg2A4tLunwPatWtXWLt2baiqqmrvRQFQzAF0++23h8WLF4d///vf2W1XJkyYEI466qjwgx/8oK0XBUAn1uan4DZu3JiFzbZt28KJJ54YLr744rBs2bLs3wBwQEmSJEnII+kw7HQ0HPnv3HPPzblmxYoVOdek1xA76mak3/zmN3OuufXWW3OuGTx4cOgITz75ZKvqfvzjH7f5ulB8GhoaQllZ2WGnuxccAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIjCzUihDb50MVczZszIuWbWrFmho/z2t7/NuWbq1Kntsi50Xm5GCkBeEkAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAp3w4YIqqurc66pq6vLueass84KrdHY2JhzzYgRI3Ku+fvf/55zDZ2Hu2EDkJcEEABRCCAAohBAAEQhgACIQgABEIUAAiAKAQRAFAIIgCgEEABRCCAAohBAAEThZqTQSfTr1y/nmhUrVrRqWb169cq55umnn8655sYbb8y5hs7DzUgByEsCCIAoBBAAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKI4Os5igVxt3Lgx55rdu3eHjjJ48OAOWxaFQQ8IgCgEEACdI4CWLFkSrrzyylBdXR1KSkrCyy+/3GJ6+vVC99xzT6iqqgrdu3cPo0ePDmvWrGnLdQagGAOosbExDB06NMyZM+eQ0x9++OHw6KOPhscffzy8++674bjjjgtjx44Ne/bsaYv1BaBYByGMGzcua4eS9n4eeeSRMGvWrHD11Vc3f0ti3759s57SxIkTv/oaA1AQ2vQa0Lp168KWLVuy024HpF+vPWzYsLB06dJD1jQ1NWVfw31wA6DwtWkApeGTSns8B0ufH5j2ebW1tVlIHWj9+/dvy1UCIE9FHwVXU1MTGhoamtuGDRtirxIAnS2AKisrs8etW7e2eD19fmDa55WWloaysrIWDYDC16YBNHDgwCxoFi5c2Pxaek0nHQ03fPjwtlwUAMU2Cm7Xrl2hvr6+xcCDlStXhoqKijBgwIAwY8aM8OCDD4bTTjstC6S77747+8zQ+PHj23rdASimAHr//ffDpZde2vx85syZ2eOkSZPC3Llzw5133pl9Vmjy5Mlh+/bt4eKLLw51dXXhmGOOads1B6BTK0nSD+/kkfSUXToaDvjqPvzww1bV9evXL+ead955J+eaESNG5FxD55EOLDvSdf3oo+AAKE4CCIAoBBAAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKIQQAB0jq9jADqPkpKSDqtLv4YFcqEHBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACicDNS6CQuvPDCnGtOOOGEVi2rqakp55qHHnqoVcuieOkBARCFAAIgCgEEQBQCCIAoBBAAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAo3IwUIujVq1fONbW1tTnXdO/ePbTGW2+91SE1FDc9IACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhZuRQgQTJ07MuWbEiBGhozz44IMdtiyKlx4QAFEIIAA6RwAtWbIkXHnllaG6ujqUlJSEl19+ucX0G264IXv94Hb55Ze35ToDUIwB1NjYGIYOHRrmzJlz2HnSwNm8eXNzmzdv3lddTwCKfRDCuHHjsnYkpaWlobKy8qusFwAFrl2uAS1atCj06dMnnHHGGWHq1Klh27Zth523qakp7Nixo0UDoPC1eQClp9+efvrpsHDhwvDQQw+FxYsXZz2mvXv3HvZ77svLy5tb//7923qVACiGzwEd/PmGc845JwwZMiSceuqpWa/osssu+8L8NTU1YebMmc3P0x6QEAIofO0+DHvQoEGhd+/eob6+/rDXi8rKylo0AApfuwfQxo0bs2tAVVVV7b0oAAr5FNyuXbta9GbWrVsXVq5cGSoqKrJ23333hWuvvTYbBbd27dpw5513hsGDB4exY8e29boDUEwB9P7774dLL720+fmB6zeTJk0Kjz32WFi1alX4wx/+ELZv3559WHXMmDHhgQceyE61AcABJUmSJCGPpIMQ0tFw0FlMmTIl55ojfZC7LU2YMKFVda+++mqbrwvFp6Gh4YjX9d0LDoAoBBAAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKIQQABEIYAAKIyv5IbOLP1KkVxNnjw555rW3IT+pZdeyrlmwYIFOddAR9EDAiAKAQRAFAIIgCgEEABRCCAAohBAAEQhgACIQgABEIUAAiAKAQRAFAIIgCgEEABRuBkpea9Xr1451zzxxBOtWtYVV1wROsIHH3yQc81NN92Uc83u3btzroGOogcEQBQCCIAoBBAAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKJwM1I61CWXXJJzzQMPPJBzzbe//e3QUf70pz/lXPOjH/0o55qdO3fmXAP5TA8IgCgEEABRCCAAohBAAEQhgACIQgABEIUAAiAKAQRAFAIIgCgEEABRCCAAohBAAEThZqS02ve+972ca1599dWca5IkCfl8Y9GrrrqqXdYFCp0eEABRCCAA8j+Aamtrw/nnnx969OgR+vTpE8aPHx9Wr17dYp49e/aEadOmhV69eoXjjz8+XHvttWHr1q1tvd4AFFMALV68OAuXZcuWhQULFoTPPvssjBkzJjQ2NjbPc9ttt4XXXnstvPjii9n8mzZtCtdcc017rDsAxTIIoa6ursXzuXPnZj2h5cuXh5EjR4aGhobw5JNPhmeffTZ85zvfyeZ56qmnwte+9rUstC688MK2XXsAivMaUBo4qYqKiuwxDaK0VzR69Ojmec4888wwYMCAsHTp0kP+jKamprBjx44WDYDC1+oA2rdvX5gxY0a46KKLwtlnn529tmXLltCtW7fQs2fPFvP27ds3m3a460rl5eXNrX///q1dJQCKIYDSa0EffPBBeO65577SCtTU1GQ9qQNtw4YNX+nnAVDAH0SdPn16eP3118OSJUtCv379ml+vrKwMn376adi+fXuLXlA6Ci6ddiilpaVZA6C4dMn1E+lp+MyfPz+8+eabYeDAgS2mn3feeaFr165h4cKFza+lw7TXr18fhg8f3nZrDUBx9YDS027pCLdXXnkl+yzQges66bWb7t27Z4833XRTmDlzZjYwoaysLNxyyy1Z+BgBB0CrA+ixxx7LHkeNGtXi9XSo9Q033JD9+1e/+lXo0qVL9gHUdITb2LFjw29+85tcFgNAEShJOvJOj/+DdBh22pMi/3344Yc51xx8zfB/1ZpddN68eaE1fv/73+dcs3v37pxrqqqqcq6ZOHFizjUrVqwIrZF+iJwQ1qxZk3PNtm3b2mVdOqN0YFl6Juxw3AsOgCgEEABRCCAAohBAAEQhgACIQgABEIUAAiAKAQRAFAIIgCgEEABRCCAAohBAAEQhgACIwt2wKci7YXekkpKSnGv8Tvtt3Lgx55ply5blXLNr167QGnfddVfONe6G/V/uhg1AXhJAAEQhgACIQgABEIUAAiAKAQRAFAIIgCgEEABRCCAAohBAAEQhgACIQgABEMXRcRZLIbjwwgtzrrnqqqtyrpk1a1bONc8991zoKKNGjcq5prKyMueaFStW5FyzadOm0Bpbt27NueZ3v/tdzjW7d+/OucbNPguHHhAAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAKIQQABEIYAAiKIkSZIk5JEdO3aE8vLy2KsBwFfU0NAQysrKDjtdDwiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIP8DqLa2Npx//vmhR48eoU+fPmH8+PFh9erVLeYZNWpUKCkpadGmTJnS1usNQDEF0OLFi8O0adPCsmXLwoIFC8Jnn30WxowZExobG1vMd/PNN4fNmzc3t4cffrit1xuATu7oXGauq6tr8Xzu3LlZT2j58uVh5MiRza8fe+yxobKysu3WEoCC0+Wrft1qqqKiosXrzzzzTOjdu3c4++yzQ01NTfjkk08O+zOampqyr+E+uAFQBJJW2rt3b/Ld7343ueiii1q8/sQTTyR1dXXJqlWrkj/+8Y/JSSedlEyYMOGwP2f27NlJuhqapmlaKKjW0NBwxBxpdQBNmTIlOfnkk5MNGzYccb6FCxdmK1JfX3/I6Xv27MlW8kBLf17sjaZpmqaFdg+gnK4BHTB9+vTw+uuvhyVLloR+/fodcd5hw4Zlj/X19eHUU0/9wvTS0tKsAVBccgqgtMd0yy23hPnz54dFixaFgQMHfmnNypUrs8eqqqrWryUAxR1A6RDsZ599NrzyyivZZ4G2bNmSvV5eXh66d+8e1q5dm02/4oorQq9evcKqVavCbbfdlo2QGzJkSHv9DgB0Rrlc9znceb6nnnoqm75+/fpk5MiRSUVFRVJaWpoMHjw4ueOOO770PODB0nljn7fUNE3TwlduX3bsL/n/YMkb6TDstEcFQOeWflSnrKzssNPdCw6AKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKAQQAFEIIACiEEAARCGAAIhCAAEQhQACIAoBBEAUAgiAKPIugJIkib0KAHTA8TzvAmjnzp2xVwGADjielyR51uXYt29f2LRpU+jRo0coKSlpMW3Hjh2hf//+YcOGDaGsrCwUK9thP9thP9thP9shf7ZDGitp+FRXV4cuXQ7fzzk65Jl0Zfv163fEedKNWsw72AG2w362w362w362Q35sh/Ly8i+dJ+9OwQFQHAQQAFF0qgAqLS0Ns2fPzh6Lme2wn+2wn+2wn+3Q+bZD3g1CAKA4dKoeEACFQwABEIUAAiAKAQRAFJ0mgObMmRNOOeWUcMwxx4Rhw4aF9957LxSbe++9N7s7xMHtzDPPDIVuyZIl4corr8w+VZ3+zi+//HKL6ek4mnvuuSdUVVWF7t27h9GjR4c1a9aEYtsON9xwwxf2j8svvzwUktra2nD++ednd0rp06dPGD9+fFi9enWLefbs2ROmTZsWevXqFY4//vhw7bXXhq1bt4Zi2w6jRo36wv4wZcqUkE86RQA9//zzYebMmdnQwhUrVoShQ4eGsWPHho8++igUm7POOits3ry5ub399tuh0DU2Nmb/5+mbkEN5+OGHw6OPPhoef/zx8O6774bjjjsu2z/SA1ExbYdUGjgH7x/z5s0LhWTx4sVZuCxbtiwsWLAgfPbZZ2HMmDHZtjngtttuC6+99lp48cUXs/nTW3tdc801odi2Q+rmm29usT+kfyt5JekELrjggmTatGnNz/fu3ZtUV1cntbW1STGZPXt2MnTo0KSYpbvs/Pnzm5/v27cvqaysTH7xi180v7Z9+/aktLQ0mTdvXlIs2yE1adKk5Oqrr06KyUcffZRti8WLFzf/33ft2jV58cUXm+f55z//mc2zdOnSpFi2Q+qSSy5Jbr311iSf5X0P6NNPPw3Lly/PTqscfL+49PnSpUtDsUlPLaWnYAYNGhSuv/76sH79+lDM1q1bF7Zs2dJi/0jvQZWepi3G/WPRokXZKZkzzjgjTJ06NWzbti0UsoaGhuyxoqIie0yPFWlv4OD9IT1NPWDAgILeHxo+tx0OeOaZZ0Lv3r3D2WefHWpqasInn3wS8kne3Yz08z7++OOwd+/e0Ldv3xavp8//9a9/hWKSHlTnzp2bHVzS7vR9990XRowYET744IPsXHAxSsMndaj948C0YpGefktPNQ0cODCsXbs2/OxnPwvjxo3LDrxHHXVUKDTpnfNnzJgRLrroouwAm0r/z7t16xZ69uxZNPvDvkNsh9QPf/jDcPLJJ2dvWFetWhXuuuuu7DrRSy+9FPJF3gcQ/5UeTA4YMmRIFkjpDvbCCy+Em266Keq6Ed/EiROb/33OOedk+8ipp56a9Youu+yyUGjSayDpm69iuA7amu0wefLkFvtDOkgn3Q/SNyfpfpEP8v4UXNp9TN+9fX4US/q8srIyFLP0Xd7pp58e6uvrQ7E6sA/YP74oPU2b/v0U4v4xffr08Prrr4e33nqrxde3pP/n6Wn77du3F8X+MP0w2+FQ0jesqXzaH/I+gNLu9HnnnRcWLlzYosuZPh8+fHgoZrt27crezaTvbIpVeropPbAcvH+kX8iVjoYr9v1j48aN2TWgQto/0vEX6UF3/vz54c0338z+/w+WHiu6du3aYn9ITzul10oLaX9IvmQ7HMrKlSuzx7zaH5JO4LnnnstGNc2dOzf5xz/+kUyePDnp2bNnsmXLlqSY/PSnP00WLVqUrFu3LvnrX/+ajB49Oundu3c2AqaQ7dy5M/nb3/6WtXSX/eUvf5n9+8MPP8ym//znP8/2h1deeSVZtWpVNhJs4MCBye7du5Ni2Q7ptNtvvz0b6ZXuH2+88UZy7rnnJqeddlqyZ8+epFBMnTo1KS8vz/4ONm/e3Nw++eST5nmmTJmSDBgwIHnzzTeT999/Pxk+fHjWCsnUL9kO9fX1yf3335/9/un+kP5tDBo0KBk5cmSSTzpFAKV+/etfZztVt27dsmHZy5YtS4rNddddl1RVVWXb4KSTTsqepztaoXvrrbeyA+7nWzrs+MBQ7Lvvvjvp27dv9kblsssuS1avXp0U03ZIDzxjxoxJTjzxxGwY8sknn5zcfPPNBfcm7VC/f9qeeuqp5nnSNx4/+clPkhNOOCE59thjkwkTJmQH52LaDuvXr8/CpqKiIvubGDx4cHLHHXckDQ0NST7xdQwARJH314AAKEwCCIAoBBAAUQggAKIQQABEIYAAiEIAARCFAAIgCgEEQBQCCIAoBBAAUQggAEIM/wcxjbpGRSMZZwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect the data whenever you can\n",
    "images, labels = next(iter(trainloader))\n",
    "pixels = images[0][0]\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a loss function!\n",
    "# We'll use cross-entropy, as we want the error in PD for all labels - again, Adam\n",
    "# optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "images = images.view(images.shape[0], -1)\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 10.261983569832578\n",
      "Epoch 1 - Training loss: 9.788969045217986\n",
      "Epoch 2 - Training loss: 9.202576841094665\n",
      "Epoch 3 - Training loss: 9.01529350819916\n",
      "Epoch 4 - Training loss: 8.311765178998828\n",
      "Epoch 5 - Training loss: 8.071117483224393\n",
      "Epoch 6 - Training loss: 7.9843048911431485\n",
      "Epoch 7 - Training loss: 7.314019673752156\n",
      "Epoch 8 - Training loss: 7.353477425118565\n",
      "Epoch 9 - Training loss: 7.0058481124386605\n",
      "Epoch 10 - Training loss: 6.838422009356762\n",
      "Epoch 11 - Training loss: 6.616815091188956\n",
      "Epoch 12 - Training loss: 6.552917083046698\n",
      "Epoch 13 - Training loss: 6.20704506094362\n",
      "Epoch 14 - Training loss: 6.317858502659987\n"
     ]
    }
   ],
   "source": [
    "# Let's start the training proper\n",
    "epochs = 15\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        # This is back-propagation explicitly being invoked!\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {:.2f} %\".format(e, running_loss/len(trainloader) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9659"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's finally test the accuracy of the validation data\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    valset,\n",
    "    batch_size=valset.data.shape[0],\n",
    "    shuffle=True\n",
    ")\n",
    "val_images, val_labels = next(iter(valloader))\n",
    "val_images = val_images.view(val_images.shape[0], -1)\n",
    "predictions = model (val_images)\n",
    "predicted_labels = np.argmax(predictions.detach().numpy(), axis=1)\n",
    "accuracy_score(val_labels.detach().numpy(), predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory ./models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Let's save this model too\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./models/torchpy_mnist_model.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.18/envs/example_1/lib/python3.9/site-packages/torch/serialization.py:628\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    625\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 628\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    629\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.18/envs/example_1/lib/python3.9/site-packages/torch/serialization.py:502\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    501\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.18/envs/example_1/lib/python3.9/site-packages/torch/serialization.py:473\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mPyTorchFileWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream))\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 473\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory ./models does not exist."
     ]
    }
   ],
   "source": [
    "# Let's save this model too\n",
    "torch.save(model, '../models/torchpy_mnist_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "example_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
